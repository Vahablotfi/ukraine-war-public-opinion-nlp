{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e079f1fc-5cb3-4ff6-8676-27e556475650",
   "metadata": {},
   "source": [
    "# Topic Modeling — Event-Based Analysis (LDA)\n",
    "\n",
    "This notebook applies topic modeling to Reddit comments related to the Ukraine war.\n",
    "The goal is to identify dominant discussion themes for each key event and examine how\n",
    "the focus of public discourse changes over time.\n",
    "\n",
    "We use Latent Dirichlet Allocation (LDA), a widely used and interpretable topic modeling\n",
    "method based on word distributions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253ccdb7-b66a-45ac-9d78-18b1ac8b5560",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04d9c25e-2685-469a-97ad-f9b8842af67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857f4b0b-d925-42f8-96bc-1829fe341d23",
   "metadata": {},
   "source": [
    "## 2. Load Event Datasets\n",
    "\n",
    "We load the same event-level CSV files used in the sentiment analysis notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cb26eb7-a405-479c-bebb-a456687c3b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'event1_kyiv': '../data/processed/event1_kyiv.csv',\n",
       " 'event2_kherson': '../data/processed/event2_kherson.csv',\n",
       " 'event3_stalemate': '../data/processed/event3_stalemate.csv',\n",
       " 'event4_trump_election': '../data/processed/event4_trump_election.csv',\n",
       " 'event5_white_house_meeting': '../data/processed/event5_white_house_meeting.csv'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir = \"../data/processed\"\n",
    "\n",
    "event_files = {\n",
    "    \"event1_kyiv\": os.path.join(base_dir, \"event1_kyiv.csv\"),\n",
    "    \"event2_kherson\": os.path.join(base_dir, \"event2_kherson.csv\"),\n",
    "    \"event3_stalemate\": os.path.join(base_dir, \"event3_stalemate.csv\"),\n",
    "    \"event4_trump_election\": os.path.join(base_dir, \"event4_trump_election.csv\"),\n",
    "    \"event5_white_house_meeting\": os.path.join(base_dir, \"event5_white_house_meeting.csv\"),\n",
    "}\n",
    "\n",
    "event_files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da850e56-d573-409c-9271-65c3e3b02620",
   "metadata": {},
   "source": [
    "## 3. Text Preparation\n",
    "\n",
    "We prepare comment text for topic modeling by:\n",
    "- keeping only non-empty comments\n",
    "- converting text to lowercase\n",
    "- removing very short comments\n",
    "\n",
    "Heavy text cleaning is intentionally avoided to preserve meaning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4699e6c-ae7c-4990-a182-a1c8d85afc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text(df):\n",
    "    df = df.copy()\n",
    "    df[\"text\"] = df[\"self_text\"].astype(str).str.lower()\n",
    "    df = df[df[\"text\"].str.len() > 30]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090b8ab1-483a-4f5c-94db-9c26a0764f03",
   "metadata": {},
   "source": [
    "## 4. Topic Modeling Function\n",
    "\n",
    "This function:\n",
    "- vectorizes text using bag-of-words\n",
    "- fits an LDA model\n",
    "- returns top words for each topic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "109c3f52-fa7a-4e58-b198-e3b13716009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lda(texts, n_topics=5, n_words=10, min_df=20):\n",
    "    vectorizer = CountVectorizer(\n",
    "        max_df=0.95,\n",
    "        min_df=min_df,\n",
    "        stop_words=custom_stopwords\n",
    "    )\n",
    "\n",
    "    dtm = vectorizer.fit_transform(texts)\n",
    "\n",
    "    lda = LatentDirichletAllocation(\n",
    "        n_components=n_topics,\n",
    "        random_state=42\n",
    "    )\n",
    "    lda.fit(dtm)\n",
    "\n",
    "    words = vectorizer.get_feature_names_out()\n",
    "\n",
    "    topics = []\n",
    "    for i, topic in enumerate(lda.components_):\n",
    "        top_words = \", \".join([words[j] for j in topic.argsort()[-n_words:]])\n",
    "        topics.append({\"topic_id\": i, \"top_words\": top_words})\n",
    "\n",
    "    return pd.DataFrame(topics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7053cd16-d4eb-4154-861b-d9622c72f3d2",
   "metadata": {},
   "source": [
    "## 4b. Refinement: Cleaning Text to Reduce Noise Topics\n",
    "\n",
    "The first LDA run can produce noise-driven topics (URLs, generic filler words like \"just\", \"like\").\n",
    "In this section, we apply light cleaning and custom stopwords, then rerun LDA to get more interpretable topics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bf76801-7700-4189-bc86-32115c17d5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "\n",
    "\n",
    "custom_stopwords = set(ENGLISH_STOP_WORDS).union({\n",
    "    # common filler / low-information words on Reddit\n",
    "    \"just\", \"like\", \"people\", \"think\", \"know\", \"really\", \"going\", \"said\", \"say\",\n",
    "    \"don\", \"doesn\", \"didn\", \"isn\", \"aren\", \"wasn\", \"weren\", \"can\", \"could\", \"would\",\n",
    "    \"im\", \"ive\", \"youre\", \"theyre\", \"were\", \"ive\", \"id\",\n",
    "\n",
    "    # reddit / quote / formatting artifacts\n",
    "    \"gt\", \"amp\", \"reddit\", \"comment\", \"comments\", \"post\", \"posts\",\n",
    "\n",
    "    # web leftovers\n",
    "    \"https\", \"http\", \"www\", \"com\",\n",
    "\n",
    "    # French stopwords \n",
    "    \"la\", \"le\", \"les\", \"et\", \"en\", \"que\", \"pas\", \"des\", \"il\", \"est\", \"un\", \"une\", \"du\", \"au\",\n",
    "\n",
    "    # common Ukraine-war generic terms (optional — helps topics be less repetitive)\n",
    "    \"ukraine\", \"russia\", \"russian\"\n",
    "})\n",
    "\n",
    "custom_stopwords = list(custom_stopwords) \n",
    "\n",
    "\n",
    "def clean_for_topics(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \" \", text)\n",
    "\n",
    "    # Remove quote artifacts and common HTML leftovers\n",
    "    text = re.sub(r\"\\bgt\\b\", \" \", text)     # often comes from \">\" quoting\n",
    "    text = re.sub(r\"\\bamp\\b\", \" \", text)\n",
    "\n",
    "    # Keep only letters and spaces\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
    "\n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb1d1c9-f67f-4da2-bb8c-1ac57c989ea8",
   "metadata": {},
   "source": [
    "## 5. Topic Modeling Per Event\n",
    "\n",
    "We run topic modeling separately for each event to allow meaningful comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "464802c3-76a3-46ba-b7dd-7611d6d2f384",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event1_kyiv: 2940 comments\n",
      "Cleaned comments kept: 2124\n",
      "Saved: ../data/processed/topics/event1_kyiv_topics.csv\n",
      "=== RAW TOPICS ===\n",
      "   topic_id                                          top_words\n",
      "0         0  udsc, ukraina, web, ua, polish, border, need, ...\n",
      "1         1  probably, want, news, ukrainian, thing, war, w...\n",
      "2         2  look, west, yes, support, propaganda, ukrainia...\n",
      "3         3  actually, world, mean, end, got, fucking, yeah...\n",
      "4         4  maybe, weapons, soldiers, love, right, militar... \n",
      "\n",
      "=== CLEANED TOPICS ===\n",
      "   topic_id                                          top_words\n",
      "0         0  used, use, weapons, children, look, troops, se...\n",
      "1         1  shit, did, fuck, way, propaganda, world, right...\n",
      "2         2  pl, visa, ua, news, ready, help, polish, borde...\n",
      "3         3  sure, power, doing, better, mean, bad, point, ...\n",
      "4         4  invasion, yes, countries, did, military, putin... \n",
      "\n",
      "Cell executed successfully\n",
      "event2_kherson: 795 comments\n",
      "Cleaned comments kept: 525\n",
      "Saved: ../data/processed/topics/event2_kherson_topics.csv\n",
      "=== RAW TOPICS ===\n",
      "   topic_id                                          top_words\n",
      "0         0  got, war, time, video, did, good, way, ukraini...\n",
      "1         1  need, sure, video, better, ukrainian, got, goo...\n",
      "2         2  sure, did, better, video, war, time, way, got,...\n",
      "3         3  need, time, sure, good, way, war, ukrainian, g...\n",
      "4         4  good, video, war, time, need, sure, got, ukrai... \n",
      "\n",
      "=== CLEANED TOPICS ===\n",
      "   topic_id                                          top_words\n",
      "0         0  way, shit, training, country, real, putin, lov...\n",
      "1         1  months, person, fucking, case, great, getting,...\n",
      "2         2  fuck, military, eject, insane, children, belie...\n",
      "3         3  doing, questions, sure, want, line, use, help,...\n",
      "4         4  old, big, thanks, got, ve, sure, work, lol, gu... \n",
      "\n",
      "Cell executed successfully\n",
      "event3_stalemate: 9955 comments\n",
      "Cleaned comments kept: 7475\n",
      "Saved: ../data/processed/topics/event3_stalemate_topics.csv\n",
      "=== RAW TOPICS ===\n",
      "   topic_id                                          top_words\n",
      "0         0  mean, right, propaganda, war, shit, believe, y...\n",
      "1         1  moscow, look, troops, wagner, way, prigozhin, ...\n",
      "2         2  training, work, ukrainian, need, experience, l...\n",
      "3         3  force, deal, army, coup, military, war, moscow...\n",
      "4         4  better, got, right, did, seen, soldiers, russi... \n",
      "\n",
      "=== CLEANED TOPICS ===\n",
      "   topic_id                                          top_words\n",
      "0         0  mod, military, deal, way, coup, wagner, power,...\n",
      "1         1  money, experience, war, work, ukrainian, milit...\n",
      "2         2  video, yeah, fight, did, ukrainian, russians, ...\n",
      "3         3  guys, sure, thing, video, got, shit, right, ru...\n",
      "4         4  force, tank, forces, probably, army, troops, m... \n",
      "\n",
      "Cell executed successfully\n",
      "event4_trump_election: 359088 comments\n",
      "Cleaned comments kept: 282838\n",
      "Saved: ../data/processed/topics/event4_trump_election_topics.csv\n",
      "=== RAW TOPICS ===\n",
      "   topic_id                                          top_words\n",
      "0         0  world, won, way, country, biden, time, want, w...\n",
      "1         1  things, want, make, way, thing, right, ve, tim...\n",
      "2         2  country, world, china, eu, nuclear, military, ...\n",
      "3         3  range, air, use, 000, long, equipment, drones,...\n",
      "4         4  ukrainian, looks, korea, nk, korean, troops, v... \n",
      "\n",
      "=== CLEANED TOPICS ===\n",
      "   topic_id                                          top_words\n",
      "0         0  need, news, lot, new, year, years, time, media...\n",
      "1         1  thing, fucking, got, time, fuck, guy, shit, ri...\n",
      "2         2  used, tanks, soldiers, hit, air, use, missiles...\n",
      "3         3  years, way, ukrainian, ukrainians, putin, want...\n",
      "4         4  china, support, weapons, military, north, euro... \n",
      "\n",
      "Cell executed successfully\n",
      "event5_white_house_meeting: 241262 comments\n",
      "Cleaned comments kept: 194205\n",
      "Saved: ../data/processed/topics/event5_white_house_meeting_topics.csv\n",
      "=== RAW TOPICS ===\n",
      "   topic_id                                          top_words\n",
      "0         0  americans, american, want, time, america, good...\n",
      "1         1  years, money, world, european, countries, mili...\n",
      "2         2  talks, zelenskyy, wants, zelensky, europe, war...\n",
      "3         3  musk, guy, time, read, ve, propaganda, media, ...\n",
      "4         4  drone, army, drones, need, russians, military,... \n",
      "\n",
      "=== CLEANED TOPICS ===\n",
      "   topic_id                                          top_words\n",
      "0         0  pro, election, american, media, elections, par...\n",
      "1         1  ll, want, maybe, right, shit, make, good, chin...\n",
      "2         2  soldiers, army, year, russians, time, years, g...\n",
      "3         3  right, fuck, good, president, time, zelensky, ...\n",
      "4         4  european, putin, countries, deal, peace, trump... \n",
      "\n",
      "Cell executed successfully\n"
     ]
    }
   ],
   "source": [
    "for event, path in event_files.items():\n",
    "    if not os.path.exists(path):\n",
    "        continue\n",
    "\n",
    "    # Load once\n",
    "    df = pd.read_csv(path, low_memory=False)\n",
    "\n",
    "    print(f\"{event}: {len(df)} comments\")\n",
    "\n",
    "    if len(df) < 500:\n",
    "        print(\"  Not enough data for reliable topic modeling\\n\")\n",
    "        continue\n",
    "\n",
    "    # ----------------------------\n",
    "    # Version 1: light cleaning\n",
    "    # ----------------------------\n",
    "    df_v1 = prepare_text(df)\n",
    "    topics_v1 = run_lda(df_v1[\"text\"], n_topics=5)\n",
    "\n",
    "    # ----------------------------\n",
    "    # Version 2: stronger cleaning\n",
    "    # ----------------------------\n",
    "    texts_v2 = (\n",
    "        df[\"self_text\"]\n",
    "        .dropna()\n",
    "        .apply(clean_for_topics)\n",
    "    )\n",
    "    texts_v2 = texts_v2[texts_v2.str.len() > 30]\n",
    "\n",
    "    # Lightweight \"mostly-English\" filter (reduces non-English topics like French)\n",
    "    common_english = r\"\\b(?:the|and|to|of|in|is|for|that|with|on|as|are)\\b\"\n",
    "    texts_v2 = texts_v2[texts_v2.str.contains(common_english, regex=True)]\n",
    "    print(\"Cleaned comments kept:\", len(texts_v2))\n",
    "\n",
    "\n",
    "    \n",
    "    min_df_event = 5 if event == \"event2_kherson\" else 20\n",
    "    topics_v2 = run_lda(texts_v2, n_topics=5, min_df=min_df_event)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    out_dir = \"../data/processed/topics\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    out_path = os.path.join(out_dir, f\"{event}_topics.csv\")\n",
    "    topics_v2.to_csv(out_path, index=False)\n",
    "    print(\"Saved:\", out_path)\n",
    "\n",
    "    print(\"=== RAW TOPICS ===\")\n",
    "    print(topics_v1, \"\\n\")\n",
    "\n",
    "    print(\"=== CLEANED TOPICS ===\")\n",
    "    print(topics_v2, \"\\n\")\n",
    "    print(\"Cell executed successfully\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad2f3e0-9eea-40e2-8a71-f4e34a192b9f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 6. Interpretation Notes\n",
    "\n",
    "- Topics represent *themes*, not opinions.\n",
    "- Topic labels are inferred from top words.\n",
    "- Differences across events indicate shifts in public focus.\n",
    "- Topic modeling complements sentiment analysis by explaining *why* tone changes.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
